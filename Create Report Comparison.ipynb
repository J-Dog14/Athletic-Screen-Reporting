{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-21T15:28:40.045403Z",
     "start_time": "2025-08-21T15:28:39.851314Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Path to the folder containing your txt files\n",
    "folder_path = 'D:/Athletic Screen 2.0/Output Files/'\n",
    "db_path = 'D:/Athletic Screen 2.0/Output Files/movement_database_v2.db'\n",
    "\n",
    "# Delete the database file if it exists to start fresh\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "    print(f\"Deleted existing database at {db_path}\")\n",
    "\n",
    "# Connect to the SQLite database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the corrected table schemas for each movement\n",
    "table_schemas = {\n",
    "    'CMJ': '''CREATE TABLE IF NOT EXISTS CMJ (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT,\n",
    "                date TEXT,\n",
    "                trial_name TEXT,\n",
    "                JH_IN REAL,\n",
    "                Peak_Power REAL,\n",
    "                PP_FORCEPLATE REAL,\n",
    "                Force_at_PP REAL,\n",
    "                Vel_at_PP REAL,\n",
    "                PP_W_per_kg REAL\n",
    "              )''',\n",
    "\n",
    "    'DJ':  '''CREATE TABLE IF NOT EXISTS DJ (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT,\n",
    "                date TEXT,\n",
    "                trial_name TEXT,\n",
    "                JH_IN REAL,\n",
    "                Peak_Power REAL,\n",
    "                PP_FORCEPLATE REAL,\n",
    "                Force_at_PP REAL,\n",
    "                Vel_at_PP REAL,\n",
    "                PP_W_per_kg REAL,\n",
    "                CT REAL,\n",
    "                RSI REAL\n",
    "              )''',\n",
    "\n",
    "    'SLV': '''CREATE TABLE IF NOT EXISTS SLV (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT,\n",
    "                date TEXT, \n",
    "                trial_name TEXT,\n",
    "                side TEXT,\n",
    "                JH_IN REAL,\n",
    "                PP_FORCEPLATE REAL,\n",
    "                Force_at_PP REAL,\n",
    "                Vel_at_PP REAL,\n",
    "                PP_W_per_kg REAL\n",
    "              )''',\n",
    "    'NMT': '''CREATE TABLE IF NOT EXISTS NMT (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                name TEXT,\n",
    "                date TEXT, \n",
    "                trial_name TEXT,\n",
    "                NUM_TAPS_10s REAL,\n",
    "                NUM_TAPS_20s REAL,\n",
    "                NUM_TAPS_30s REAL,\n",
    "                NUM_TAPS REAL\n",
    "              )'''\n",
    "}\n",
    "\n",
    "# Create the tables in the database (if they don't exist)\n",
    "for schema in table_schemas.values():\n",
    "    cursor.execute(schema)\n",
    "\n",
    "# Function to extract the client's name from the first line of the file\n",
    "def extract_name(line):\n",
    "    match = re.search(r'Data\\\\(.*?)[_\\\\]', line)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_date(line):\n",
    "    \"\"\"\n",
    "    Looks for a segment like 2025-05-22_ in the first-line path returned by Cortex.\n",
    "    Returns '2025-05-22' or None if not found.\n",
    "    \"\"\"\n",
    "    m = re.search(r'\\\\(\\d{4}-\\d{2}-\\d{2})_', line)\n",
    "    return m.group(1) if m else None\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Function to insert data into the appropriate table\n",
    "def insert_data_into_table(table_name, name, trial_name, variables):\n",
    "    \"\"\"\n",
    "    `variables` still contains the leading dummy “1”.\n",
    "    After we drop that each txt gives:\n",
    "        CMJ : 8 numbers\n",
    "        DJ  : 8 numbers\n",
    "        SLV : 6 numbers\n",
    "        NMT : 4 numbers\n",
    "    We pick only the columns we store.\n",
    "    \"\"\"\n",
    "    v = variables[1:]          # drop the leading “1”\n",
    "\n",
    "    if table_name == 'CMJ':\n",
    "        # keep indices 0,1,4,5,6,7  (→ six values)\n",
    "        vals = [v[i] for i in (0, 1, 4, 5, 6, 7)]\n",
    "        cursor.execute(\n",
    "            \"\"\"INSERT INTO CMJ\n",
    "               (name, date, trial_name,\n",
    "                JH_IN, Peak_Power,\n",
    "                PP_FORCEPLATE, Force_at_PP, Vel_at_PP,\n",
    "                PP_W_per_kg)\n",
    "               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (name, date, trial_name, *vals)\n",
    "        )\n",
    "\n",
    "    elif table_name == 'DJ':\n",
    "        # keep every value (8 numbers)\n",
    "        cursor.execute(\n",
    "            \"\"\"INSERT INTO DJ\n",
    "               (name, date, trial_name,\n",
    "                JH_IN, Peak_Power,\n",
    "                PP_FORCEPLATE, Force_at_PP, Vel_at_PP,\n",
    "                CT, RSI, PP_W_per_kg)\n",
    "               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (name, date, trial_name, *v)        # 8 numbers + 2 strings = 10\n",
    "        )\n",
    "\n",
    "    elif table_name == 'SLV':\n",
    "        side = 'Left' if 'SLVL' in trial_name else 'Right'\n",
    "        # keep indices 0,2,3,4,5  (→ five values)\n",
    "        vals = [v[i] for i in (0, 2, 3, 4, 5)]\n",
    "        cursor.execute(\n",
    "            \"\"\"INSERT INTO SLV\n",
    "               (name, date, trial_name, side,\n",
    "                JH_IN,\n",
    "                PP_FORCEPLATE, Force_at_PP, Vel_at_PP,\n",
    "                PP_W_per_kg)\n",
    "               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (name, date, trial_name, side, *vals)\n",
    "        )\n",
    "\n",
    "    elif table_name == 'NMT':\n",
    "        cursor.execute(\n",
    "            \"\"\"INSERT INTO NMT\n",
    "               (name, date, trial_name,\n",
    "                NUM_TAPS_10s, NUM_TAPS_20s, NUM_TAPS_30s, NUM_TAPS)\n",
    "               VALUES (?, ?, ?, ?, ?, ?, ?)\"\"\",\n",
    "            (name, date, trial_name, *v)\n",
    "        )\n",
    "# Loop through the txt files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        trial_name = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        # Determine which table the file belongs to\n",
    "        if 'CMJ' in trial_name:\n",
    "            table_name = 'CMJ'\n",
    "        elif 'DJ' in trial_name:\n",
    "            table_name = 'DJ'\n",
    "        elif 'SLVL' in trial_name or 'SLVR' in trial_name:\n",
    "            table_name = 'SLV'\n",
    "        elif 'NMT' in trial_name:\n",
    "            table_name = 'NMT'\n",
    "        else:\n",
    "            continue  # Skip any files that don't match the naming pattern\n",
    "\n",
    "        # Load the data from the txt file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                # Extract the name from the first line\n",
    "                first_line = f.readline().strip()\n",
    "                name = extract_name(first_line)\n",
    "                date = extract_date(first_line)\n",
    "\n",
    "                # Print the extracted name to verify\n",
    "                print(f\"File: {file_name}, Extracted Name: {name}\")\n",
    "\n",
    "                if not name:\n",
    "                    print(f\"Name extraction failed for {file_name}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Read all lines until we find the line with the actual numeric data\n",
    "                # --- replace the old for-loop (line_num, line) with this: -------------------\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                \n",
    "                    if re.match(r'^[-+]?\\d', line):          # first real numeric row\n",
    "                        variables = [float(v) for v in line.split()]\n",
    "                        print(f\"Processing file: {file_name}, Variables: {variables}\")\n",
    "                        insert_data_into_table(table_name, name, trial_name, variables)\n",
    "                        break\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error with file {file_name}: {e}\")\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data successfully inserted into the database.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing database at D:/Athletic Screen 2.0/Output Files/movement_database_v2.db\n",
      "File: CMJ1.txt, Extracted Name: Justin Zachery\n",
      "Processing file: CMJ1.txt, Variables: [1.0, 19.4, 423.0, 2.0, 211.0, 526.5, 1849.74, 284.62, 6.58]\n",
      "File: CMJ1_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: CMJ1_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file CMJ1_Power.txt: list index out of range\n",
      "File: CMJ2.txt, Extracted Name: Justin Zachery\n",
      "Processing file: CMJ2.txt, Variables: [1.0, 20.8, 455.0, 2.07, 220.0, 607.3, 1815.21, 334.55, 7.59]\n",
      "File: CMJ2_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: CMJ2_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file CMJ2_Power.txt: list index out of range\n",
      "File: CMJ3.txt, Extracted Name: Justin Zachery\n",
      "Processing file: CMJ3.txt, Variables: [1.0, 19.4, 423.0, 2.0, 211.0, 526.5, 1849.74, 284.62, 6.58]\n",
      "File: CMJ3_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: CMJ3_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file CMJ3_Power.txt: list index out of range\n",
      "File: DJ1.txt, Extracted Name: Justin Zachery\n",
      "Processing file: DJ1.txt, Variables: [1.0, 21.9, 2904.0, 862.1, 2192.17, 393.26, 0.44, 2.56, 10.78]\n",
      "File: DJ1_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: DJ1_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file DJ1_Power.txt: Incorrect number of bindings supplied. The current statement uses 11, and there are 4 supplied.\n",
      "File: DJ2.txt, Extracted Name: Justin Zachery\n",
      "Processing file: DJ2.txt, Variables: [1.0, 6650.0, 894.9, 2346.26, 381.41, 0.38, 11.19]\n",
      "Unexpected error with file DJ2.txt: Incorrect number of bindings supplied. The current statement uses 11, and there are 9 supplied.\n",
      "File: DJ2_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: DJ2_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file DJ2_Power.txt: Incorrect number of bindings supplied. The current statement uses 11, and there are 4 supplied.\n",
      "File: SLVL1.txt, Extracted Name: Justin Zachery\n",
      "Processing file: SLVL1.txt, Variables: [1.0, 11.6, 6524.0, 454.9, 1933.0, 235.3, 5.69]\n",
      "File: SLVL1_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: SLVL1_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file SLVL1_Power.txt: list index out of range\n",
      "File: SLVL2.txt, Extracted Name: Justin Zachery\n",
      "Processing file: SLVL2.txt, Variables: [1.0, 11.4, 6500.0, 377.7, 1775.8, 212.7, 4.72]\n",
      "File: SLVL2_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: SLVL2_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file SLVL2_Power.txt: list index out of range\n",
      "File: SLVR1.txt, Extracted Name: Justin Zachery\n",
      "Processing file: SLVR1.txt, Variables: [1.0, 11.7, 6549.0, 443.2, 1804.7, 245.6, 5.54]\n",
      "File: SLVR1_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: SLVR1_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file SLVR1_Power.txt: list index out of range\n",
      "File: SLVR2.txt, Extracted Name: Justin Zachery\n",
      "Processing file: SLVR2.txt, Variables: [1.0, 11.3, 6475.0, 440.2, 1767.0, 249.1, 5.5]\n",
      "File: SLVR2_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: SLVR2_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file SLVR2_Power.txt: list index out of range\n",
      "File: DJ3.txt, Extracted Name: Justin Zachery\n",
      "Processing file: DJ3.txt, Variables: [1.0, 23.4, 4668.0, 948.1, 2489.42, 380.87, 0.34, 3.52, 11.85]\n",
      "File: DJ3_Power.txt, Extracted Name: Lily Devia\n",
      "Processing file: DJ3_Power.txt, Variables: [1.0, 0.0]\n",
      "Unexpected error with file DJ3_Power.txt: Incorrect number of bindings supplied. The current statement uses 11, and there are 4 supplied.\n",
      "Data successfully inserted into the database.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:28:58.973927Z",
     "start_time": "2025-08-21T15:28:40.047494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Create a longitudinal “comparison” report for a single athlete.\n",
    "\n",
    "• Reads every assessment for that athlete from Athletic_Screen_All_data_v2.db\n",
    "• Builds one small line-chart per metric (dates on x-axis, metric on y-axis)\n",
    "• Keeps your existing scatter-plots (Force@PP vs Vel@PP) – but now draws **all**\n",
    "  dots, one per assessment day\n",
    "• Calculates %-change between the last two assessments and writes it under\n",
    "  each chart\n",
    "• Saves the report with a unique, date-stamped filename (won’t overwrite)\n",
    "-------------------------------------------------------------------------------\n",
    "Dependencies:\n",
    "  pip install matplotlib pandas scipy python-docx docx2txt pillow\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "from datetime import date\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# -------------------------  CONFIGURABLE PATHS  ---------------------------- #\n",
    "# --------------------------------------------------------------------------- #\n",
    "DB_PATH      = r'D:\\Athletic Screen 2.0\\Output Files\\Athletic_Screen_All_data_v2.db'\n",
    "REPORTS_DIR  = r'G:\\My Drive\\Athletic Screen 2.0 Reports\\Comparison Reports'\n",
    "LOGO_PATH    = r'8ctane Baseball - Black abd Blue BG.jpeg'      # adjust if needed\n",
    "IMG_DIR_NAME = \"Images\"                                         # sub-folder for pngs\n",
    "\n",
    "# ---- fetch the only athlete in the temp DB -------------------------------\n",
    "temp_db = r'D:\\Athletic Screen 2.0\\Output Files\\movement_database_v2.db'\n",
    "with sqlite3.connect(temp_db) as tmp_conn:\n",
    "    tmp_cur = tmp_conn.cursor()\n",
    "    name_row = tmp_cur.execute(\"SELECT DISTINCT name FROM CMJ\").fetchone()\n",
    "    if not name_row:\n",
    "        raise SystemExit(\"No athlete found in movement_database_v2.db\")\n",
    "    CLIENT_NAME = name_row[0]\n",
    "\n",
    "\n",
    "# ------------- open DB ------------------------------------------------------ #\n",
    "conn   = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# quick sanity-check – is the athlete in CMJ at all?\n",
    "cursor.execute(\"SELECT COUNT(*) FROM CMJ WHERE name = ?\", (CLIENT_NAME,))\n",
    "if cursor.fetchone()[0] == 0:\n",
    "    raise SystemExit(f\"No rows for '{CLIENT_NAME}' in the All-data DB.\")\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                HELPER – fetch each table into a tidy DataFrame              #\n",
    "# --------------------------------------------------------------------------- #\n",
    "TABLE_METRICS = {\n",
    "    \"CMJ\": [\"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "            \"Force_at_PP\", \"Vel_at_PP\"],\n",
    "    \"DJ\" : [\"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "            \"Force_at_PP\", \"Vel_at_PP\", \"CT\", \"RSI\"],\n",
    "    \"SLV\": [\"side\",  # keep side to split later\n",
    "            \"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "            \"Force_at_PP\", \"Vel_at_PP\"],\n",
    "    \"NMT\": [\"NUM_TAPS_10s\"],\n",
    "}\n",
    "\n",
    "def load_table(table: str) -> pd.DataFrame:\n",
    "    cols = [\"date\"] + TABLE_METRICS[table]\n",
    "    sql  = f\"SELECT {', '.join(cols)} FROM {table} WHERE name = ? ORDER BY date\"\n",
    "    df   = pd.read_sql_query(sql, conn, params=(CLIENT_NAME,))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                         PLOTTING HELPERS                                    #\n",
    "# --------------------------------------------------------------------------- #\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\": \"#181818\",\n",
    "    \"axes.facecolor\"  : \"#303030\",\n",
    "    \"axes.edgecolor\"  : \"white\",\n",
    "    \"axes.labelcolor\" : \"slategrey\",\n",
    "    \"xtick.color\"     : \"lightgrey\",\n",
    "    \"ytick.color\"     : \"lightgrey\",\n",
    "    \"grid.color\"      : \"dimgrey\",\n",
    "    \"text.color\"      : \"white\",\n",
    "})\n",
    "\n",
    "def scatter_trend(df: pd.DataFrame, metric: str, table: str, out_path: str):\n",
    "    \"\"\"\n",
    "    • Plots every individual trial as grey dots\n",
    "    • Plots the *mean of each assessment date* as large coloured dots\n",
    "    • Draws a trend-line that connects ONLY the first-date mean ➝ last-date mean\n",
    "    • Adds a text-box with:\n",
    "        – mean for each date\n",
    "        – %Δ (last vs first)\n",
    "        – percentile of each mean vs all-athlete reference distribution\n",
    "    \"\"\"\n",
    "    # ---- reference distribution for percentile ----------------------------\n",
    "    ref_vals = pd.read_sql_query(\n",
    "        f\"SELECT {metric} FROM {table} WHERE {metric} IS NOT NULL\",\n",
    "        conn\n",
    "    )[metric].astype(float).values\n",
    "\n",
    "    by_day = (df.groupby('date')[metric]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .sort_values('date'))\n",
    "    # colours: first = blue, last = orange (mid dates = grey if present)\n",
    "    colours = ['cornflowerblue']*len(by_day)\n",
    "    colours[-1] = 'orange'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # raw trials\n",
    "    ax.scatter(df['date'], df[metric], s=25, c='grey', alpha=.4)\n",
    "\n",
    "    # date means\n",
    "    ax.scatter(by_day['date'], by_day[metric],\n",
    "               s=100, c=colours, edgecolors='black', zorder=3)\n",
    "\n",
    "    # trend line first ➝ last\n",
    "    ax.plot(by_day['date'].iloc[[0, -1]],\n",
    "            by_day[metric].iloc[[0, -1]],\n",
    "            c='white', ls='--', lw=2)\n",
    "\n",
    "    # % change\n",
    "    pct_change = (by_day[metric].iloc[-1] - by_day[metric].iloc[0]) \\\n",
    "                 / by_day[metric].iloc[0]\n",
    "    pct_txt = f\"%Δ: {pct_change:+.1%}\"\n",
    "    pct_col = \"lime\" if pct_change > 0 else \"tomato\"\n",
    "\n",
    "    # text-box --------------------------------------------------------------\n",
    "    lines = [pct_txt]\n",
    "    for d, v in zip(by_day['date'], by_day[metric]):\n",
    "        prc = stats.percentileofscore(ref_vals, v)\n",
    "        lines.append(f\"{d.date()}: {v:.2f}  ({prc:.0f}ᵗʰ)\")\n",
    "    txt = \"\\n\".join(lines)\n",
    "\n",
    "    ax.text(0.98, 0.02, txt,\n",
    "            transform=ax.transAxes,\n",
    "            va='bottom', ha='right',\n",
    "            fontsize=9, color='white',\n",
    "            bbox=dict(facecolor=\"#181818\",\n",
    "                      edgecolor=\"#404040\", pad=5))\n",
    "\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(metric.replace('_', ' '))\n",
    "    fig.autofmt_xdate()\n",
    "    ax.grid(True)\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def scatter_force_vel(df: pd.DataFrame, force_col: str, vel_col: str,\n",
    "                      table: str, title: str, out_path: str):\n",
    "    \"\"\"\n",
    "    Reference dots (all athletes) in pale grey.\n",
    "    Athlete dots coloured by date (earlier→later = dark→bright).\n",
    "    \"\"\"\n",
    "    # reference cloud -------------------------------------------------------\n",
    "    ref = pd.read_sql_query(\n",
    "        f\"SELECT {force_col}, {vel_col} FROM {table} \"\n",
    "        f\"WHERE {force_col} IS NOT NULL AND {vel_col} IS NOT NULL\",\n",
    "        conn\n",
    "    ).astype(float)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.scatter(ref[force_col], ref[vel_col],\n",
    "               c='lightgrey', s=15, alpha=.4, label='Reference')\n",
    "\n",
    "    # athlete dots ----------------------------------------------------------\n",
    "    dates_ord = pd.to_datetime(df['date']).map(pd.Timestamp.toordinal)\n",
    "    sc = ax.scatter(df[force_col], df[vel_col],\n",
    "                    c=dates_ord, cmap='viridis',\n",
    "                    s=80, edgecolors='black', label='Athlete')\n",
    "\n",
    "    ax.set_xlabel(force_col.replace('_', ' '))\n",
    "    ax.set_ylabel(vel_col.replace('_', ' '))\n",
    "    ax.set_title(title, color='white', fontsize=10, pad=10)\n",
    "    ax.grid(True)\n",
    "    fig.colorbar(sc, ax=ax, label='Date (ordinal)')\n",
    "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                     DOCX PREPARATION                                        #\n",
    "# --------------------------------------------------------------------------- #\n",
    "# build export paths (date-stamped, no overwrite)\n",
    "latest_date = cursor.execute(\n",
    "    \"SELECT MAX(date) FROM CMJ WHERE name = ?\", (CLIENT_NAME,)\n",
    ").fetchone()[0] or date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "parts = CLIENT_NAME.split(', ')\n",
    "client_name_rev = f\"{parts[1]}_{parts[0]}\" if len(parts)==2 else CLIENT_NAME\n",
    "base_name = f\"Comparison_Report_{client_name_rev}_{latest_date}\"\n",
    "\n",
    "reports_dir = os.path.abspath(REPORTS_DIR)\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "docx_path = os.path.join(reports_dir, base_name + \".docx\")\n",
    "img_root  = os.path.join(reports_dir, IMG_DIR_NAME, base_name)\n",
    "os.makedirs(img_root, exist_ok=True)\n",
    "\n",
    "i = 1\n",
    "while os.path.exists(docx_path):\n",
    "    docx_path = os.path.join(reports_dir, f\"{base_name}_{i}.docx\")\n",
    "    img_root  = os.path.join(reports_dir, IMG_DIR_NAME, f\"{base_name}_{i}\")\n",
    "    os.makedirs(img_root, exist_ok=True)\n",
    "    i += 1\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                        GENERATE THE REPORT                                  #\n",
    "# --------------------------------------------------------------------------- #\n",
    "doc = Document()\n",
    "if os.path.exists(LOGO_PATH):\n",
    "    doc.add_picture(LOGO_PATH, width=Inches(4.0))\n",
    "    doc.paragraphs[-1].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "\n",
    "doc.add_heading(\"Athlete Longitudinal Report\", level=1)\n",
    "doc.add_paragraph(f\"Athlete:  {CLIENT_NAME}\")\n",
    "doc.add_paragraph(f\"Generated: {date.today().strftime('%B %d, %Y')}\")\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "\n",
    "    # -------------- CMJ ----------------------------------------------------- #\n",
    "    df_cmj = load_table(\"CMJ\")\n",
    "    if not df_cmj.empty:\n",
    "        doc.add_heading(\"CMJ\", level=2)\n",
    "\n",
    "        for m in [\"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "                  \"Force_at_PP\", \"Vel_at_PP\"]:\n",
    "            plot_path = os.path.join(tmpdir, f\"CMJ_{m}.png\")\n",
    "            scatter_trend(df_cmj, m, \"CMJ\", plot_path)\n",
    "            doc.add_paragraph(m.replace('_',' '), style='Heading 3')\n",
    "            doc.add_picture(plot_path, width=Inches(5.5))\n",
    "\n",
    "        # scatter        -------------------\n",
    "        scat = os.path.join(tmpdir, \"CMJ_force_vel.png\")\n",
    "        scatter_force_vel(df_cmj, \"Force_at_PP\", \"Vel_at_PP\", \"CMJ\",\n",
    "                          \"CMJ Force vs Velocity\", scat)\n",
    "        doc.add_paragraph(\"Force vs Velocity\", style='Heading 3')\n",
    "        doc.add_picture(scat, width=Inches(5.5))\n",
    "\n",
    "    # -------------- DJ ------------------------------------------------------ #\n",
    "    df_dj = load_table(\"DJ\")\n",
    "    if not df_dj.empty:\n",
    "        doc.add_page_break()\n",
    "        doc.add_heading(\"DJ\", level=2)\n",
    "\n",
    "        for m in [\"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "                  \"Force_at_PP\", \"Vel_at_PP\", \"CT\", \"RSI\"]:\n",
    "            if m not in df_dj.columns:   # some metrics optional\n",
    "                continue\n",
    "            plot_path = os.path.join(tmpdir, f\"DJ_{m}.png\")\n",
    "            scatter_trend(df_dj, m, \"DJ\", plot_path)\n",
    "            doc.add_paragraph(m.replace('_',' '), style='Heading 3')\n",
    "            doc.add_picture(plot_path, width=Inches(5.5))\n",
    "\n",
    "        scat = os.path.join(tmpdir, \"DJ_force_vel.png\")\n",
    "        scatter_force_vel(df_dj, \"Force_at_PP\", \"Vel_at_PP\", \"DJ\",\n",
    "                          \"DJ Force vs Velocity\", scat)\n",
    "        doc.add_paragraph(\"Force vs Velocity\", style='Heading 3')\n",
    "        doc.add_picture(scat, width=Inches(5.5))\n",
    "\n",
    "    # -------------- SLV (split sides) --------------------------------------- #\n",
    "    df_slv = load_table(\"SLV\")\n",
    "    if not df_slv.empty:\n",
    "        doc.add_page_break()\n",
    "        doc.add_heading(\"Single-Leg Vertical (SLV)\", level=2)\n",
    "\n",
    "        for side in [\"Left\", \"Right\"]:\n",
    "            sub = df_slv[df_slv['side']==side].copy()\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            doc.add_heading(f\"{side} leg\", level=3)\n",
    "            for m in [\"JH_IN\", \"PP_FORCEPLATE\", \"PP_W_per_kg\",\n",
    "                      \"Force_at_PP\", \"Vel_at_PP\"]:\n",
    "                plot_path = os.path.join(tmpdir, f\"SLV_{side}_{m}.png\")\n",
    "                scatter_trend(sub, m, \"SLV\", plot_path)\n",
    "                doc.add_paragraph(m.replace('_',' '), style='Heading 4')\n",
    "                doc.add_picture(plot_path, width=Inches(5.0))\n",
    "\n",
    "        # scatter – one colour per date (left & right merged)\n",
    "        scat = os.path.join(tmpdir, \"SLV_force_vel.png\")\n",
    "        scatter_force_vel(df_slv, \"Force_at_PP\", \"Vel_at_PP\", \"SLV\",\n",
    "                          \"SLV Force vs Velocity\", scat)\n",
    "        doc.add_heading(\"Force vs Velocity (both legs)\", level=3)\n",
    "        doc.add_picture(scat, width=Inches(5.5))\n",
    "\n",
    "    # -------------- NMT ----------------------------------------------------- #\n",
    "    df_nmt = load_table(\"NMT\")\n",
    "    if not df_nmt.empty:\n",
    "        doc.add_page_break()\n",
    "        doc.add_heading(\"Neuromuscular Taps (NMT)\", level=2)\n",
    "\n",
    "        plot_path = os.path.join(tmpdir, \"NMT_taps.png\")\n",
    "        scatter_trend(df_nmt, \"NUM_TAPS_10s\", \"NMT\", plot_path)\n",
    "        doc.add_paragraph(\"Number of taps in 10 s\", style='Heading 3')\n",
    "        doc.add_picture(plot_path, width=Inches(5.5))\n",
    "        \n",
    "    # ---- SAVE DOCX before tmpdir disappears ----\n",
    "    doc.save(docx_path)\n",
    "    print(f\"✅  Report saved to\\n    {docx_path}\")\n",
    "\n",
    "conn.close()\n",
    "print(\"Comparison Completed\")\n",
    "\n",
    "# Path to the folder containing ASCII .txt files\n",
    "ascii_folder = r\"D:/Athletic Screen 2.0/Output Files/\"\n",
    "\n",
    "# Remove all .txt files in the ascii_folder\n",
    "for filename in os.listdir(ascii_folder):\n",
    "    if filename.lower().endswith(\".txt\"):\n",
    "        file_path = os.path.join(ascii_folder, filename)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "print(\"All ASCII .txt files cleared after ingestion.\")\n"
   ],
   "id": "5eade438dbe9cb26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Report saved to\n",
      "    G:\\My Drive\\Athletic Screen 2.0 Reports\\Comparison Reports\\Comparison_Report_Justin Zachery_2025-05-22.docx\n",
      "Comparison Completed\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ1.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ1_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ2.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ2_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ3.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/CMJ3_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ1.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ1_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ2.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ2_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVL1.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVL1_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVL2.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVL2_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVR1.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVR1_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVR2.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/SLVR2_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/PPU1.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/PPU1_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/PPU2.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/PPU2_Power.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ3.txt\n",
      "Deleted: D:/Athletic Screen 2.0/Output Files/DJ3_Power.txt\n",
      "All ASCII .txt files cleared after ingestion.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T15:28:58.978612Z",
     "start_time": "2025-08-21T15:28:58.974430Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "544684ad1e0bcbdd",
   "outputs": [],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
